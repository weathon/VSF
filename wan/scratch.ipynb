{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e745ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import AutoencoderKLWan\n",
    "from diffusers.utils import export_to_video\n",
    "from processor import WanAttnProcessor2_0\n",
    "from pipeline import WanPipeline \n",
    "# Available models: Wan-AI/Wan2.1-T2V-14B-Diffusers, Wan-AI/Wan2.1-T2V-1.3B-Diffusers\n",
    "model_id = \"Wan-AI/Wan2.1-T2V-1.3B-Diffusers\"\n",
    "vae = AutoencoderKLWan.from_pretrained(model_id, subfolder=\"vae\", torch_dtype=torch.float32)\n",
    "pipe = WanPipeline.from_pretrained(model_id, vae=vae, torch_dtype=torch.bfloat16)\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206aa429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "prompt = \"A cat and a dog baking a cake together in a kitchen. The cat is carefully measuring flour, while the dog is stirring the batter with a wooden spoon. The kitchen is cozy, with sunlight streaming through the window.\"\n",
    "neg_prompt = \"low quality, blurry, bad lighting, weird motion\"\n",
    "pos_prompt_embeds, _ = pipe.encode_prompt(\n",
    "    prompt=prompt,\n",
    "    do_classifier_free_guidance=False\n",
    ")\n",
    "\n",
    "\n",
    "neg_prompt_embeds, _ = pipe.encode_prompt(\n",
    "    prompt=neg_prompt,\n",
    "    padding=False,\n",
    "    do_classifier_free_guidance=False,\n",
    ")\n",
    "neg_len = neg_prompt_embeds.shape[1]\n",
    "pos_len = pos_prompt_embeds.shape[1]\n",
    "\n",
    "mask = None\n",
    "# torch.zeros((1, 14040, pos_len+neg_len)).cuda()\n",
    "# mask[:, :, -neg_len:] = -0.8\n",
    "\n",
    "for block in pipe.transformer.blocks:\n",
    "    block.attn2.processor = WanAttnProcessor2_0(scale=0.3, neg_prompt_length=neg_len, attn_mask=mask)\n",
    "\n",
    "prompt_embeds = torch.cat([pos_prompt_embeds, neg_prompt_embeds], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41d3d469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f96541816a4e9fa9dbb3d05e594d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output.mp4'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pipe(\n",
    "    prompt_embeds=prompt_embeds,\n",
    "    height=480,\n",
    "    width=832,\n",
    "    num_frames=81,\n",
    "    num_inference_steps=50,\n",
    "    guidance_scale=0.0,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(0),\n",
    ").frames[0] \n",
    "export_to_video(output, \"output.mp4\", fps=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
